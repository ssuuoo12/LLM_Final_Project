import os
import json
import pickle
import pandas as pd
import random
from sqlalchemy import create_engine, text
from langchain_ollama import ChatOllama
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from tqdm import tqdm

# DB ì—°ê²° ì„¤ì •
DB_URL = "mysql+pymysql://nask8543:tnsrb0313!@223.26.253.91:3306/test"
engine = create_engine(DB_URL)

# ì„ë² ë”© ëª¨ë¸ê³¼ LLM ì •ì˜
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
llm = ChatOllama(model="gemma3")

# ì§ˆë¬¸-ë‹µë³€ ìŒ ë¡œë”© í•¨ìˆ˜ (ìƒ˜í”Œë§ ì ìš©)
def load_medical_qa_qa_pairs(sample_limit=50000):
    question_base = "app/dataset/medical_qa/question"
    answer_base = "app/dataset/medical_qa/answer"

    print("ğŸ“¥ ì§ˆë¬¸ íŒŒì¼ ë¡œë”© ì‹œì‘...")
    q_map = {}
    question_files = []
    for root, _, files in os.walk(question_base):
        for file in files:
            if file.endswith(".json"):
                question_files.append(os.path.join(root, file))
    random.shuffle(question_files)

    for q_file in tqdm(question_files, desc="ğŸ“„ ì§ˆë¬¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘"):
        try:
            with open(q_file, "r", encoding="utf-8") as f:
                q_data = json.load(f)
                key = (
                    q_data.get("disease_category", ""),
                    q_data.get("disease_name", {}).get("kor", ""),
                    q_data.get("intention", "")
                )
                question = q_data.get("question", "").strip()
                if question:
                    q_map.setdefault(key, []).append(question)
        except Exception as e:
            print(f"ì§ˆë¬¸ íŒŒì¼ ì˜¤ë¥˜: {q_file} - {e}")

    print(f"ì§ˆë¬¸ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {sum(len(v) for v in q_map.values()):,}ê±´")

    print("ë‹µë³€ íŒŒì¼ ë¡œë”© ì‹œì‘...")
    qa_pairs = []
    answer_files = []
    for root, _, files in os.walk(answer_base):
        for file in files:
            if file.endswith(".json"):
                answer_files.append(os.path.join(root, file))
    random.shuffle(answer_files)

    for a_file in tqdm(answer_files, desc="ğŸ§¾ ë‹µë³€ íŒŒì¼ ì²˜ë¦¬ ì¤‘"):
        if len(qa_pairs) >= sample_limit:
            break

        try:
            with open(a_file, "r", encoding="utf-8") as f:
                a_data = json.load(f)
                key = (
                    a_data.get("disease_category", ""),
                    a_data.get("disease_name", {}).get("kor", ""),
                    a_data.get("intention", "")
                )
                answer_parts = a_data.get("answer", {})
                answer_text = " ".join([answer_parts.get(k, "") for k in ["intro", "body", "conclusion"]]).strip()

                questions = q_map.get(key, [])
                for q in questions:
                    if q and answer_text:
                        qa_pairs.append((q, answer_text))
                        if len(qa_pairs) >= sample_limit:
                            break
        except Exception as e:
            print(f"ë‹µë³€ íŒŒì¼ ì˜¤ë¥˜: {a_file} - {e}")

    print(f"ìƒ˜í”Œë§ëœ ì§ˆë¬¸-ë‹µë³€ ìŒ: {len(qa_pairs):,}ê°œ")
    return qa_pairs

# FAISS ë³‘í•© ìˆ˜ë™ êµ¬í˜„ í•¨ìˆ˜
def manual_merge_vectorstores(vectorstores):
    if not vectorstores:
        return None
    base = vectorstores[0]
    for vs in vectorstores[1:]:
        base.merge_from(vs)
    return base

def load_medical_vectorstore():
    path = "app/vector_index/medical_faiss_store_sample"
    if os.path.exists(path):
        print(f"medical vectorstore ë¡œë“œ ì¤‘: {path}")
        return FAISS.load_local(path, embeddings=embedding_model, allow_dangerous_deserialization=True)
    print("medical vectorstoreê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return None

# ë³´í—˜ ë²¡í„° ì¸ë±ìŠ¤ ë¡œë“œ
def load_insurance_vectorstore():
    path = "app/vector_index/insurance_faiss_store"
    return FAISS.load_local(path, embeddings=embedding_model, allow_dangerous_deserialization=True)

# ë²¡í„°ìŠ¤í† ì–´ ì„ íƒ (source ê¸°ë°˜)
def load_vectorstore(source: str):
    if source == "insurance":
        return load_insurance_vectorstore()
    elif source == "medical":
        return load_medical_vectorstore()
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” sourceì…ë‹ˆë‹¤ (insurance / medical)")

# RAG + LLM ê¸°ë°˜ ë‹µë³€ ìƒì„±
prompt_template = """
ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê±´ê°• ìƒë‹´ AIì…ë‹ˆë‹¤. ì•„ë˜ ì°¸ê³  ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë¶€ë“œëŸ½ê²Œ ë‹µí•´ì£¼ì„¸ìš”.

[ì°¸ê³  ì •ë³´]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
"""

def ask_llm(user_id: str, message: str, source: str = "medical") -> str:
    print("ğŸ¤– RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘...")
    vectorstore = load_vectorstore(source)
    docs = vectorstore.similarity_search(message, k=3) if vectorstore else []

    # medicalì—ì„œ ëª» ì°¾ìœ¼ë©´ insuranceë¡œ fallback
    if not docs and source == "medical":
        print("ğŸ”„ medicalì—ì„œ ê²°ê³¼ ì—†ìŒ â†’ insurance fallback")
        vectorstore = load_vectorstore("insurance")
        docs = vectorstore.similarity_search(message, k=3) if vectorstore else []

    if docs:
        context = "\n".join([
            doc.page_content + "\n" + doc.metadata.get("answer", "") 
            for doc in docs
        ])
        prompt = prompt_template.format(context=context, question=message)
        raw = llm.invoke(prompt)
    else:
        print("ìœ ì‚¬ ë¬¸ì„œ ì—†ìŒ â†’ LLM ë‹¨ë… ì‘ë‹µ")
        raw = llm.invoke(message)

    # í•µì‹¬: contentë§Œ ì¶”ì¶œ
    answer = raw.content if hasattr(raw, "content") else str(raw)

    save_chat_history(user_id, message, answer)
    return answer


# ì±„íŒ… ì´ë ¥ ì €ì¥
def save_chat_history(user_id: str, question: str, answer: str):
    question = question.strip().lower()
    answer = answer.strip().lower()
    
    with engine.connect() as conn:
        result = conn.execute(
            text("SELECT COUNT(*) FROM chat_history WHERE user_id=:user_id AND LOWER(TRIM(message))=:message AND LOWER(TRIM(response))=:response"),
            {"user_id": user_id, "message": question, "response": answer}
        )
        count = result.scalar()
        if count == 0:
            conn.execute(
                text("INSERT INTO chat_history (user_id, message, response) VALUES (:user_id, :message, :response)"),
                {"user_id": user_id, "message": question, "response": answer}
            )
            conn.commit()
            print("ì±„íŒ… ì´ë ¥ ì €ì¥ ì™„ë£Œ")
        else:
            print("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë ¥ - ì €ì¥ ìƒëµ")


# âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ (insurance / medical)
'''
def build_faiss_store(source: str):
    if source == "insurance":
        df = pd.read_csv("app/dataset/insurance_qar.csv")
        qa_pairs = [(row["question"], row["answer"] + " ì¶”ì²œìƒí’ˆ: " + row["recommended_product"]) for _, row in df.iterrows()]
        print(f"ğŸ” {source} ì§ˆë¬¸ {len(qa_pairs):,}ê±´ ì„ë² ë”© ì‹œì‘...")
        docs = [Document(page_content=q, metadata={"answer": a}) for q, a in tqdm(qa_pairs, desc="ğŸ“„ ë¬¸ì„œ ë³€í™˜ ì¤‘")]
        vectorstore = FAISS.from_documents(docs, embedding_model)
        save_path = f"app/vector_index/{source}_faiss_store"
        vectorstore.save_local(save_path)
        with open(f"app/vector_index/questions_{source}.pkl", "wb") as f:
            pickle.dump(qa_pairs, f)
        print(f"ë³´í—˜ ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {save_path}")

    elif source == "medical":
        qa_pairs = load_medical_qa_qa_pairs(sample_limit=50000)
        print(f"ğŸ” {source} ì§ˆë¬¸ {len(qa_pairs):,}ê±´ ì„ë² ë”© ì‹œì‘...")
        docs = [Document(page_content=q, metadata={"answer": a}) for q, a in tqdm(qa_pairs, desc="ğŸ“„ ë¬¸ì„œ ë³€í™˜ ì¤‘ (ìƒ˜í”Œ)")]
        vectorstore = FAISS.from_documents(docs, embedding_model)
        save_path = f"app/vector_index/{source}_faiss_store_sample"
        vectorstore.save_local(save_path)
        with open(f"app/vector_index/questions_{source}_sample.pkl", "wb") as f:
            pickle.dump(qa_pairs, f)
        print(f"ì˜ë£Œ ìƒ˜í”Œ ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {save_path}")

    else:
        raise ValueError("ì§€ì›ë˜ëŠ” sourceëŠ” 'insurance' ë˜ëŠ” 'medical'ì…ë‹ˆë‹¤.")
        '''